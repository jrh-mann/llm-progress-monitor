{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccf9856b",
   "metadata": {},
   "source": [
    "Just run all these cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9965467",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a976724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!pip install nnsight -q\\n!pip install einops -q\\n!pip install ipywidgets -q\\n!pip install hf_transfer -q\\n!pip install plotly -q\\n!pip install anywidget -q\\n# Ensure widget extensions are enabled\\n!jupyter nbextension enable --py widgetsnbextension --sys-prefix 2>/dev/null || true'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''!pip install nnsight -q\n",
    "!pip install einops -q\n",
    "!pip install ipywidgets -q\n",
    "!pip install hf_transfer -q\n",
    "!pip install plotly -q\n",
    "!pip install anywidget -q\n",
    "# Ensure widget extensions are enabled\n",
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix 2>/dev/null || true'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b74a3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension --sys-prefix 2>/dev/null || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08b669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnsight import LanguageModel\n",
    "from einops import einsum\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import time\n",
    "import numpy as np\n",
    "import nnsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0571272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>console.log('Widgets initialized')</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable widget display in Jupyter\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# This ensures widgets are properly rendered\n",
    "display(HTML(\"<script>console.log('Widgets initialized')</script>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561baa29",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec2e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89ba94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_tensor = torch.load('rollouts-big/beta_torch.pt').to(torch.bfloat16)\n",
    "model_name = 'Qwen/Qwen3-4B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable compilation warnings since we use dynamic control flow\n",
    "model = LanguageModel(model_name, device_map=device, dtype=torch.bfloat16, dispatch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f67b7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ema_preds(log_preds, alpha=0.5):\n",
    "    given_alpha = alpha\n",
    "    preds_list = log_preds.tolist()\n",
    "    \n",
    "    ema_preds = []\n",
    "    cur_ema = None\n",
    "    for i,pred in enumerate(preds_list):\n",
    "        # Use a smooth transition from 0.5 to given_alpha, reaching given_alpha at 200 tokens\n",
    "        alpha = given_alpha\n",
    "        if cur_ema is None:\n",
    "            cur_ema = pred\n",
    "        else:\n",
    "            cur_ema = alpha*(cur_ema-1) + (1-alpha)*pred #-1 because we have stepped one token\n",
    "        ema_preds.append(cur_ema)\n",
    "    return ema_preds\n",
    "def get_log_preds(activation, weight_tensor):\n",
    "    return einsum(activation, weight_tensor, 'seq d_model, d_model -> seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4231cba7",
   "metadata": {},
   "source": [
    "# Vibe coded UIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "447d7ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f642212052f4b22b754c1a518321088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Text Generation Progress</h3>'), Textarea(value='', description='Prompt:', layoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input text box for prompt\n",
    "prompt_input = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder='Enter your prompt here...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "# Create submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Generate Text',\n",
    "    button_style='success',\n",
    "    tooltip='Click to start text generation',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "# Create progress bar widget\n",
    "progress_bar = widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#20B2AA'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "# Create percentage label\n",
    "percentage_label = widgets.HTML(\n",
    "    value=\"<b>0.0%</b>\",\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create horizontal box for progress bar and percentage\n",
    "progress_row = widgets.HBox([progress_bar, percentage_label])\n",
    "\n",
    "# Create text widget for token display\n",
    "token_display = widgets.HTML(\n",
    "    value=\"<b>Generated tokens will appear here...</b>\",\n",
    "    placeholder='',\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create container for the widgets\n",
    "progress_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Text Generation Progress</h3>\"),\n",
    "    prompt_input,\n",
    "    submit_button,\n",
    "    progress_row,\n",
    "    token_display\n",
    "])\n",
    "\n",
    "# Display the widget\n",
    "display(progress_container)\n",
    "\n",
    "def on_submit_clicked(b):\n",
    "    # Reset progress\n",
    "    progress_bar.value = 0\n",
    "    percentage_label.value = \"<b>0.0%</b>\"\n",
    "    token_display.value = \"<b>Generating...</b>\"\n",
    "    \n",
    "    # Get prompt from input\n",
    "    prompt = prompt_input.value\n",
    "    # Apply chat template\n",
    "    prompt = model.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    cur_log_preds = []\n",
    "    n_tokens_generated = 0\n",
    "    generated_tokens = []\n",
    "\n",
    "    with model.generate(prompt, max_new_tokens=32768, do_sample=True) as tracer:\n",
    "        # Call .all() to apply intervention to each new token\n",
    "        with tracer.all():\n",
    "            activations = model.model.layers[15].output[0]\n",
    "            if len(activations.shape) == 1:\n",
    "                activations = activations.unsqueeze(0)\n",
    "            preds = get_log_preds(activations, weight_tensor).tolist()\n",
    "            if len(preds) > 1:\n",
    "                pass\n",
    "            else:\n",
    "                cur_log_preds+=preds\n",
    "                ema_preds = get_ema_preds(torch.tensor(cur_log_preds))\n",
    "                n_tokens_generated+=1\n",
    "                pred_tokens_remaining = ema_preds[-1]\n",
    "                pred_percent_through = n_tokens_generated/(n_tokens_generated + pred_tokens_remaining)\n",
    "                \n",
    "                token = model.lm_head.output.argmax(dim=-1).tolist()\n",
    "                token_str = model.tokenizer.decode(token[0][0], skip_special_tokens=False)\n",
    "                generated_tokens.append(token_str)\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.value = pred_percent_through * 100\n",
    "                \n",
    "                # Update percentage label\n",
    "                percentage_label.value = f\"<b>{pred_percent_through*100:.1f}%</b>\"\n",
    "                \n",
    "                # Update token display with all generated tokens\n",
    "                tokens_html = \" \".join([f\"<span style='background-color: #e6f3ff; padding: 2px 4px; margin: 1px; border-radius: 3px;'>{token}</span>\" for token in generated_tokens])\n",
    "                token_display.value = f\"<b>Generated tokens:</b><br>{tokens_html}<br><br><b>Latest:</b> '{token_str}' | <b>Predicted:</b> {pred_percent_through*100:.1f}% through\"\n",
    "\n",
    "# Connect button click to function\n",
    "submit_button.on_click(on_submit_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5fc6bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3368b447b90b4a2c840e3869138a2969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Text Generation Progress</h3>'), Textarea(value='', description='Prompt:', layoâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input text box for prompt\n",
    "prompt_input = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder='Enter your prompt here...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "# Create submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Generate Text',\n",
    "    button_style='success',\n",
    "    tooltip='Click to start text generation',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "# Create progress bar widget\n",
    "progress_bar = widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#20B2AA'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "# Create percentage label\n",
    "percentage_label = widgets.HTML(\n",
    "    value=\"<b>0.0%</b>\",\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create horizontal box for progress bar and percentage\n",
    "progress_row = widgets.HBox([progress_bar, percentage_label])\n",
    "\n",
    "# Create text widget for token display\n",
    "token_display = widgets.HTML(\n",
    "    value=\"<b>Generated tokens will appear here...</b>\",\n",
    "    placeholder='',\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create output widget for the graph\n",
    "graph_output = widgets.Output()\n",
    "\n",
    "# Create container for the widgets - graph now above token display\n",
    "progress_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Text Generation Progress</h3>\"),\n",
    "    prompt_input,\n",
    "    submit_button,\n",
    "    progress_row,\n",
    "    graph_output,\n",
    "    token_display\n",
    "])\n",
    "\n",
    "# Display the widget\n",
    "display(progress_container)\n",
    "\n",
    "# Initialize FigureWidget outside the loop (Option 2)\n",
    "import plotly.graph_objects as go\n",
    "fig_widget = None\n",
    "\n",
    "def get_color_for_change(change, max_change=800.0):\n",
    "    \"\"\"\n",
    "    Get color based on change in predictions.\n",
    "    Positive change (increase) -> Red\n",
    "    Negative change (decrease) -> Green\n",
    "    \"\"\"\n",
    "    # Normalize change to [-1, 1] range\n",
    "    normalized = max(min(change / max_change, 1.0), -1.0)\n",
    "    \n",
    "    if normalized > 0:  # Increase - Red\n",
    "        # Interpolate from light to dark red\n",
    "        intensity = int(255 * (1 - normalized * 0.7))  # 255 to ~77\n",
    "        return f'rgb(255, {intensity}, {intensity})'\n",
    "    else:  # Decrease - Green\n",
    "        # Interpolate from light to dark green\n",
    "        intensity = int(255 * (1 + normalized * 0.7))  # 255 to ~77\n",
    "        return f'rgb({intensity}, 255, {intensity})'\n",
    "\n",
    "def calculate_ema(values, alpha=0.2):\n",
    "    \"\"\"Calculate exponential moving average\n",
    "    Lower alpha = smoother (e.g., 0.1-0.3 for good smoothing)\n",
    "    Higher alpha = follows data more closely (e.g., 0.8-1.0)\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return []\n",
    "    ema = [values[0]]\n",
    "    for val in values[1:]:\n",
    "        ema.append(alpha * val + (1 - alpha) * ema[-1])\n",
    "    return ema\n",
    "\n",
    "def on_submit_clicked(b):\n",
    "    import html\n",
    "    global fig_widget\n",
    "    \n",
    "    # Reset progress\n",
    "    progress_bar.value = 0\n",
    "    percentage_label.value = \"<b>0.0%</b>\"\n",
    "    token_display.value = \"<b>Generating...</b>\"\n",
    "    \n",
    "    # Initialize FigureWidget once with both traces\n",
    "    with graph_output:\n",
    "        graph_output.clear_output(wait=True)\n",
    "        fig_widget = go.FigureWidget()\n",
    "        # Add EMA trace first (will be behind)\n",
    "        fig_widget.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode='lines',\n",
    "            name='EMA (smoothed)',\n",
    "            line=dict(color='rgba(255, 100, 100, 0.6)', width=3),\n",
    "            showlegend=True\n",
    "        ))\n",
    "        # Add main trace on top\n",
    "        fig_widget.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode='lines',\n",
    "            name='Predicted Tokens Remaining',\n",
    "            line=dict(color='rgba(32, 178, 170, 0.8)', width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "        fig_widget.update_layout(\n",
    "            title='Predicted Tokens Remaining Over Time',\n",
    "            xaxis_title='Token Number',\n",
    "            yaxis_title='Predicted Tokens Remaining',\n",
    "            height=300,\n",
    "            margin=dict(l=50, r=20, t=40, b=40),\n",
    "            transition_duration=0,\n",
    "            legend=dict(x=0.7, y=1, bgcolor='rgba(255,255,255,0.8)')\n",
    "        )\n",
    "        display(fig_widget)\n",
    "    \n",
    "    # Get prompt from input\n",
    "    prompt = prompt_input.value\n",
    "    # Apply chat template\n",
    "    prompt = model.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    raw_preds = []  # Store raw predictions without EMA\n",
    "    cur_log_preds = []  # Store predictions after get_ema_preds (for progress bar)\n",
    "    generated_tokens = []\n",
    "    token_changes = []  # Track changes for color coding\n",
    "\n",
    "    with model.generate(prompt, max_new_tokens=32768, do_sample=True) as tracer:\n",
    "        # Call .all() to apply intervention to each new token\n",
    "        with tracer.all():\n",
    "            activations = model.model.layers[15].output[0]\n",
    "            if activations.shape[0] == 1:\n",
    "                if len(raw_preds) > 0:\n",
    "                    preds = get_log_preds(activations, weight_tensor)\n",
    "                    exp_preds = torch.exp(preds).item()\n",
    "\n",
    "                    raw_preds.append(exp_preds)\n",
    "                \n",
    "                    cur_log_preds = calculate_ema(raw_preds, alpha=0.2)\n",
    "                \n",
    "                    change = cur_log_preds[-1] - cur_log_preds[-2]\n",
    "                    token_changes.append(change)\n",
    "\n",
    "                    token = model.lm_head.output.argmax(dim=-1).tolist()\n",
    "                    token_str = model.tokenizer.decode(token[0][0], skip_special_tokens=False)\n",
    "                    generated_tokens.append(token_str)\n",
    "            \n",
    "                    pred_percent_through = len(raw_preds) / (len(raw_preds) + cur_log_preds[-1]) * 100\n",
    "                    progress_bar.value = pred_percent_through\n",
    "            \n",
    "                    percentage_label.value = f\"<b>{pred_percent_through:.1f}%</b>\"\n",
    "            \n",
    "                    start_idx = max(0, len(generated_tokens) - 2000)\n",
    "                    display_tokens = generated_tokens[start_idx:]\n",
    "                    display_changes = token_changes[start_idx:]\n",
    "                \n",
    "                    # Calculate dynamic max_change based on actual data\n",
    "                    max_change = max(abs(c) for c in token_changes) if token_changes else 800.0\n",
    "                    max_change = max(max_change, 100.0)  # Ensure a minimum threshold\n",
    "                \n",
    "                    tokens_html = \" \".join([\n",
    "                        f\"<span style='background-color: {get_color_for_change(change, max_change)}; padding: 2px 4px; margin: 1px; border-radius: 3px;' title='Token #{start_idx + i + 1} | Change: {change:+.2f}'>{html.escape(token)}</span>\" \n",
    "                        for i, (token, change) in enumerate(zip(display_tokens, display_changes))\n",
    "                    ])\n",
    "                \n",
    "                    # Add indicator if tokens are truncated\n",
    "                    truncated_msg = f\"<i>(Showing last 2000 of {len(generated_tokens)} tokens)</i><br>\" if len(generated_tokens) > 2000 else \"\"\n",
    "                \n",
    "                    token_display.value = f\"<b>Generated tokens:</b> <span style='font-size: 0.9em;'>(ðŸ”´ increase / ðŸŸ¢ decrease)</span><br>{truncated_msg}{tokens_html}<br><br><b>Latest:</b> '{html.escape(token_str)}' | <b>Predicted:</b> {pred_percent_through:.1f}% through\"\n",
    "                \n",
    "                    if len(cur_log_preds) % 10 == 0 or len(cur_log_preds) == 1:\n",
    "                        x_values = list(range(1, len(cur_log_preds) + 1))\n",
    "                    \n",
    "                        with fig_widget.batch_update():\n",
    "                            # Trace 0 is EMA (red line)\n",
    "                            fig_widget.data[0].x = x_values\n",
    "                            fig_widget.data[0].y = cur_log_preds\n",
    "                            # Trace 1 is raw predictions (teal line)\n",
    "                            fig_widget.data[1].x = x_values\n",
    "                            fig_widget.data[1].y = raw_preds\n",
    "                \n",
    "                else:\n",
    "                    preds = get_log_preds(activations, weight_tensor)\n",
    "                    exp_preds = torch.exp(preds).item()\n",
    "\n",
    "                    raw_preds.append(exp_preds)\n",
    "\n",
    "                \n",
    "submit_button.on_click(on_submit_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc7cf8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ddae686e364522a127b58619550ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Text Generation Progress with Steering</h3>'), Textarea(value='', description='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de11fbbab6944f0a63df09f92554278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input text box for prompt\n",
    "prompt_input = widgets.Textarea(\n",
    "    value=\"\",\n",
    "    placeholder='Enter your prompt here...',\n",
    "    description='Prompt:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "# Create submit button\n",
    "submit_button = widgets.Button(\n",
    "    description='Generate Text',\n",
    "    button_style='success',\n",
    "    tooltip='Click to start text generation',\n",
    "    icon='play'\n",
    ")\n",
    "\n",
    "# Create progress bar widget\n",
    "progress_bar = widgets.FloatProgress(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    description='Progress:',\n",
    "    bar_style='info',\n",
    "    style={'bar_color': '#20B2AA'},\n",
    "    orientation='horizontal'\n",
    ")\n",
    "\n",
    "# Create percentage label\n",
    "percentage_label = widgets.HTML(\n",
    "    value=\"<b>0.0%</b>\",\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create horizontal box for progress bar and percentage\n",
    "progress_row = widgets.HBox([progress_bar, percentage_label])\n",
    "\n",
    "# Create text widget for token display\n",
    "token_display = widgets.HTML(\n",
    "    value=\"<b>Generated tokens will appear here...</b>\",\n",
    "    placeholder='',\n",
    "    description='',\n",
    ")\n",
    "\n",
    "# Create output widget for the graph\n",
    "graph_output = widgets.Output()\n",
    "\n",
    "# Create steering strength slider\n",
    "steering_slider = widgets.FloatSlider(\n",
    "    value=0.0,\n",
    "    min=-10.0,\n",
    "    max=10.0,\n",
    "    step=0.1,\n",
    "    description='Steering:',\n",
    "    tooltip='Positive = steer toward completion, Negative = steer away from completion',\n",
    "    style={'description_width': '80px'},\n",
    "    layout=widgets.Layout(width='100%')\n",
    ")\n",
    "\n",
    "# Create container for the widgets - graph now above token display\n",
    "progress_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>Text Generation Progress with Steering</h3>\"),\n",
    "    prompt_input,\n",
    "    steering_slider,\n",
    "    submit_button,\n",
    "    progress_row,\n",
    "    graph_output,\n",
    "    token_display\n",
    "])\n",
    "\n",
    "# Display the widget\n",
    "display(progress_container)\n",
    "\n",
    "# Initialize FigureWidget outside the loop (Option 2)\n",
    "import plotly.graph_objects as go\n",
    "fig_widget = None\n",
    "\n",
    "def get_color_for_change(change, max_change=800.0):\n",
    "    \"\"\"\n",
    "    Get color based on change in predictions.\n",
    "    Positive change (increase) -> Red\n",
    "    Negative change (decrease) -> Green\n",
    "    \"\"\"\n",
    "    # Normalize change to [-1, 1] range\n",
    "    normalized = max(min(change / max_change, 1.0), -1.0)\n",
    "    \n",
    "    if normalized > 0:  # Increase - Red\n",
    "        # Interpolate from light to dark red\n",
    "        intensity = int(255 * (1 - normalized * 0.7))  # 255 to ~77\n",
    "        return f'rgb(255, {intensity}, {intensity})'\n",
    "    else:  # Decrease - Green\n",
    "        # Interpolate from light to dark green\n",
    "        intensity = int(255 * (1 + normalized * 0.7))  # 255 to ~77\n",
    "        return f'rgb({intensity}, 255, {intensity})'\n",
    "\n",
    "def calculate_ema(values, alpha=0.2):\n",
    "    \"\"\"Calculate exponential moving average\n",
    "    Lower alpha = smoother (e.g., 0.1-0.3 for good smoothing)\n",
    "    Higher alpha = follows data more closely (e.g., 0.8-1.0)\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        return []\n",
    "    ema = [values[0]]\n",
    "    for val in values[1:]:\n",
    "        ema.append(alpha * val + (1 - alpha) * ema[-1])\n",
    "    return ema\n",
    "\n",
    "def on_submit_clicked(b):\n",
    "    import html\n",
    "    global fig_widget\n",
    "    \n",
    "    # Get steering strength from slider\n",
    "    steering_strength = steering_slider.value\n",
    "    \n",
    "    # Reset progress\n",
    "    progress_bar.value = 0\n",
    "    percentage_label.value = \"<b>0.0%</b>\"\n",
    "    token_display.value = f\"<b>Generating... (Steering: {steering_strength:+.1f})</b>\"\n",
    "    \n",
    "    # Initialize FigureWidget once with both traces\n",
    "    with graph_output:\n",
    "        graph_output.clear_output(wait=True)\n",
    "        fig_widget = go.FigureWidget()\n",
    "        # Add EMA trace first (will be behind)\n",
    "        fig_widget.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode='lines',\n",
    "            name='EMA (smoothed)',\n",
    "            line=dict(color='rgba(255, 100, 100, 0.6)', width=3),\n",
    "            showlegend=True\n",
    "        ))\n",
    "        # Add main trace on top\n",
    "        fig_widget.add_trace(go.Scatter(\n",
    "            x=[],\n",
    "            y=[],\n",
    "            mode='lines',\n",
    "            name='Predicted Tokens Remaining',\n",
    "            line=dict(color='rgba(32, 178, 170, 0.8)', width=2),\n",
    "            showlegend=True\n",
    "        ))\n",
    "        fig_widget.update_layout(\n",
    "            title=f'Predicted Tokens Remaining Over Time (Steering: {steering_strength:+.1f})',\n",
    "            xaxis_title='Token Number',\n",
    "            yaxis_title='Predicted Tokens Remaining',\n",
    "            height=300,\n",
    "            margin=dict(l=50, r=20, t=40, b=40),\n",
    "            transition_duration=0,\n",
    "            legend=dict(x=0.7, y=1, bgcolor='rgba(255,255,255,0.8)')\n",
    "        )\n",
    "        display(fig_widget)\n",
    "    \n",
    "    # Get prompt from input\n",
    "    prompt = prompt_input.value\n",
    "    # Apply chat template\n",
    "    prompt = model.tokenizer.apply_chat_template([{\"role\": \"user\", \"content\": prompt}], tokenize=False, add_generation_prompt=True)\n",
    "    raw_preds = []  # Store raw predictions without EMA\n",
    "    cur_log_preds = []  # Store predictions after get_ema_preds (for progress bar)\n",
    "    generated_tokens = []\n",
    "    token_changes = []  # Track changes for color coding\n",
    "\n",
    "    with model.generate(prompt, max_new_tokens=32768, do_sample=True) as tracer:\n",
    "        # Call .all() to apply intervention to each new token\n",
    "        with tracer.all():\n",
    "            # Get the original activations\n",
    "            original_activations = model.model.layers[15].output[0]\n",
    "            \n",
    "            # Apply steering to modify the forward pass (affects generation)\n",
    "            if steering_strength != 0.0:\n",
    "                model.model.layers[15].output[0][:] = original_activations + steering_strength * weight_tensor\n",
    "            \n",
    "            # Use ORIGINAL activations for prediction (measure effect on unsteered state)\n",
    "            activations = original_activations\n",
    "                        \n",
    "            if activations.shape[0] == 1:\n",
    "                if len(raw_preds) > 0:\n",
    "                    preds = get_log_preds(activations, weight_tensor)\n",
    "                    exp_preds = torch.exp(preds).item()\n",
    "\n",
    "                    raw_preds.append(exp_preds)\n",
    "                \n",
    "                    cur_log_preds = calculate_ema(raw_preds, alpha=0.2)\n",
    "                \n",
    "                    change = cur_log_preds[-1] - cur_log_preds[-2]\n",
    "                    token_changes.append(change)\n",
    "\n",
    "                    token = model.lm_head.output.argmax(dim=-1).tolist()\n",
    "                    token_str = model.tokenizer.decode(token[0][0], skip_special_tokens=False)\n",
    "                    generated_tokens.append(token_str)\n",
    "            \n",
    "                    pred_percent_through = len(raw_preds) / (len(raw_preds) + cur_log_preds[-1]) * 100\n",
    "                    progress_bar.value = pred_percent_through\n",
    "            \n",
    "                    percentage_label.value = f\"<b>{pred_percent_through:.1f}%</b>\"\n",
    "            \n",
    "                    start_idx = max(0, len(generated_tokens) - 2000)\n",
    "                    display_tokens = generated_tokens[start_idx:]\n",
    "                    display_changes = token_changes[start_idx:]\n",
    "                \n",
    "                    # Calculate dynamic max_change based on actual data\n",
    "                    max_change = max(abs(c) for c in token_changes) if token_changes else 800.0\n",
    "                    max_change = max(max_change, 100.0)  # Ensure a minimum threshold\n",
    "                \n",
    "                    tokens_html = \" \".join([\n",
    "                        f\"<span style='background-color: {get_color_for_change(change, max_change)}; padding: 2px 4px; margin: 1px; border-radius: 3px;' title='Token #{start_idx + i + 1} | Change: {change:+.2f}'>{html.escape(token)}</span>\" \n",
    "                        for i, (token, change) in enumerate(zip(display_tokens, display_changes))\n",
    "                    ])\n",
    "                \n",
    "                    # Add indicator if tokens are truncated\n",
    "                    truncated_msg = f\"<i>(Showing last 2000 of {len(generated_tokens)} tokens)</i><br>\" if len(generated_tokens) > 2000 else \"\"\n",
    "                \n",
    "                    token_display.value = f\"<b>Generated tokens:</b> <span style='font-size: 0.9em;'>(ðŸ”´ increase / ðŸŸ¢ decrease)</span> | <b>Steering: {steering_strength:+.1f}</b><br>{truncated_msg}{tokens_html}<br><br><b>Latest:</b> '{html.escape(token_str)}' | <b>Predicted:</b> {pred_percent_through:.1f}% through\"\n",
    "                \n",
    "                    if len(cur_log_preds) % 10 == 0 or len(cur_log_preds) == 1:\n",
    "                        x_values = list(range(1, len(cur_log_preds) + 1))\n",
    "                    \n",
    "                        with fig_widget.batch_update():\n",
    "                            # Trace 0 is EMA (red line)\n",
    "                            fig_widget.data[0].x = x_values\n",
    "                            fig_widget.data[0].y = cur_log_preds\n",
    "                            # Trace 1 is raw predictions (teal line)\n",
    "                            fig_widget.data[1].x = x_values\n",
    "                            fig_widget.data[1].y = raw_preds\n",
    "                \n",
    "                else:\n",
    "                    preds = get_log_preds(activations, weight_tensor)\n",
    "                    exp_preds = torch.exp(preds).item()\n",
    "\n",
    "                    raw_preds.append(exp_preds)\n",
    "                \n",
    "submit_button.on_click(on_submit_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5005a9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1934, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_tensor.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c339692b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c795cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPROVED: Unbiased analysis that filters low-count tokens\n",
    "def analyze_token_distributions_robust(baseline_tokens, steered_up_tokens, steered_down_tokens, \n",
    "                                       min_total_count=10, top_n=100):\n",
    "    \"\"\"\n",
    "    Robust analysis that filters out tokens with insufficient data.\n",
    "    \n",
    "    Args:\n",
    "        baseline_tokens: List of tokens from baseline condition\n",
    "        steered_up_tokens: List of tokens from steered up condition  \n",
    "        steered_down_tokens: List of tokens from steered down condition\n",
    "        min_total_count: Minimum total appearances across all conditions to be included\n",
    "        top_n: Number of top results to return\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with token statistics and enrichment scores\n",
    "    \"\"\"\n",
    "    # Count frequencies\n",
    "    baseline_counts = Counter(baseline_tokens)\n",
    "    up_counts = Counter(steered_up_tokens)\n",
    "    down_counts = Counter(steered_down_tokens)\n",
    "    \n",
    "    # Get all unique tokens\n",
    "    all_tokens = set(baseline_counts.keys()) | set(up_counts.keys()) | set(down_counts.keys())\n",
    "    \n",
    "    # Total counts for normalization\n",
    "    baseline_total = len(baseline_tokens)\n",
    "    up_total = len(steered_up_tokens)\n",
    "    down_total = len(steered_down_tokens)\n",
    "    \n",
    "    print(f\"\\nAnalysis Parameters:\")\n",
    "    print(f\"  Baseline tokens: {baseline_total:,}\")\n",
    "    print(f\"  Steered Up tokens: {up_total:,}\")\n",
    "    print(f\"  Steered Down tokens: {down_total:,}\")\n",
    "    print(f\"  Unique tokens found: {len(all_tokens):,}\")\n",
    "    print(f\"  Minimum total count filter: {min_total_count}\")\n",
    "    \n",
    "    # Build analysis dataframe\n",
    "    data = []\n",
    "    filtered_out = 0\n",
    "    \n",
    "    for token in all_tokens:\n",
    "        b_count = baseline_counts[token]\n",
    "        u_count = up_counts[token]\n",
    "        d_count = down_counts[token]\n",
    "        \n",
    "        total_count = b_count + u_count + d_count\n",
    "        \n",
    "        # FILTER: Skip tokens with insufficient total occurrences\n",
    "        if total_count < min_total_count:\n",
    "            filtered_out += 1\n",
    "            continue\n",
    "        \n",
    "        baseline_freq = b_count / baseline_total\n",
    "        up_freq = u_count / up_total\n",
    "        down_freq = d_count / down_total\n",
    "        \n",
    "        # Use Laplace smoothing with count-based pseudocount (more robust)\n",
    "        # Add 1 to counts, add 3 to totals (equivalent to adding 1 to each condition)\n",
    "        pseudocount = 1\n",
    "        up_enrichment = np.log2(\n",
    "            ((u_count + pseudocount) / (up_total + 3)) / \n",
    "            ((b_count + pseudocount) / (baseline_total + 3))\n",
    "        )\n",
    "        down_enrichment = np.log2(\n",
    "            ((d_count + pseudocount) / (down_total + 3)) / \n",
    "            ((b_count + pseudocount) / (baseline_total + 3))\n",
    "        )\n",
    "        \n",
    "        # Chi-square test for up vs baseline\n",
    "        from scipy.stats import chi2_contingency\n",
    "        contingency_up = [[u_count, up_total - u_count], \n",
    "                          [b_count, baseline_total - b_count]]\n",
    "        chi2_up, p_up = chi2_contingency(contingency_up)[:2]\n",
    "        \n",
    "        contingency_down = [[d_count, down_total - d_count], \n",
    "                            [b_count, baseline_total - b_count]]\n",
    "        chi2_down, p_down = chi2_contingency(contingency_down)[:2]\n",
    "        \n",
    "        data.append({\n",
    "            'token': token,\n",
    "            'total_count': total_count,\n",
    "            'baseline_count': b_count,\n",
    "            'up_count': u_count,\n",
    "            'down_count': d_count,\n",
    "            'baseline_freq': baseline_freq,\n",
    "            'up_freq': up_freq,\n",
    "            'down_freq': down_freq,\n",
    "            'up_enrichment': up_enrichment,\n",
    "            'down_enrichment': down_enrichment,\n",
    "            'up_vs_down': up_enrichment - down_enrichment,\n",
    "            'up_pvalue': p_up,\n",
    "            'down_pvalue': p_down,\n",
    "            # Flag significant results (p < 0.01 after Bonferroni correction)\n",
    "            'up_significant': p_up < (0.01 / len(all_tokens)),\n",
    "            'down_significant': p_down < (0.01 / len(all_tokens))\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    print(f\"  Tokens after filtering: {len(df):,}\")\n",
    "    print(f\"  Tokens filtered out: {filtered_out:,}\")\n",
    "    \n",
    "    # Sort by different metrics\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"MOST ENRICHED IN STEERED UP (positive steering = toward completion)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Token':<30} | {'Up Count':>8} | {'Base Count':>10} | {'Enrich':>7} | {'P-value':>10} | Sig?\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    top_up = df.nlargest(top_n, 'up_enrichment')\n",
    "    for idx, row in top_up.head(30).iterrows():\n",
    "        sig_marker = \"***\" if row['up_significant'] else \"\"\n",
    "        print(f\"{row['token'][:30]:30s} | {row['up_count']:8d} | {row['baseline_count']:10d} | \"\n",
    "              f\"{row['up_enrichment']:+7.2f} | {row['up_pvalue']:10.2e} | {sig_marker:3s}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"MOST ENRICHED IN STEERED DOWN (negative steering = away from completion)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Token':<30} | {'Down Count':>10} | {'Base Count':>10} | {'Enrich':>7} | {'P-value':>10} | Sig?\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    top_down = df.nlargest(top_n, 'down_enrichment')\n",
    "    for idx, row in top_down.head(30).iterrows():\n",
    "        sig_marker = \"***\" if row['down_significant'] else \"\"\n",
    "        print(f\"{row['token'][:30]:30s} | {row['down_count']:10d} | {row['baseline_count']:10d} | \"\n",
    "              f\"{row['down_enrichment']:+7.2f} | {row['down_pvalue']:10.2e} | {sig_marker:3s}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"MOST DEPLETED IN STEERED UP (avoided when steering toward completion)\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Token':<30} | {'Up Count':>8} | {'Base Count':>10} | {'Depletion':>9}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    bottom_up = df.nsmallest(top_n, 'up_enrichment')\n",
    "    for idx, row in bottom_up.head(30).iterrows():\n",
    "        print(f\"{row['token'][:30]:30s} | {row['up_count']:8d} | {row['baseline_count']:10d} | \"\n",
    "              f\"{row['up_enrichment']:+9.2f}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "873f658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading instructions from rollouts-big/Qwen3-4B-2.json...\n",
      "Loaded 5,000 unique instructions\n",
      "Loaded 5,000 unique instructions\n"
     ]
    }
   ],
   "source": [
    "# Load instructions from rollouts for batched generation\n",
    "import json\n",
    "import random\n",
    "\n",
    "print(\"Loading instructions from rollouts-big/Qwen3-4B-2.json...\")\n",
    "with open('/root/llm-progress-monitor/rollouts-big/Qwen3-4B-2.json', 'r') as f:\n",
    "    rollouts_data = json.load(f)\n",
    "\n",
    "# Extract unique instructions\n",
    "instructions = list(set([item['instruction'] for item in rollouts_data]))\n",
    "print(f\"Loaded {len(instructions):,} unique instructions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512835ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECOMMENDED: Ultra-efficient version following nnsight best practices\n",
    "# This version is the cleanest and most efficient\n",
    "\n",
    "def generate_batched_tokens(steering_strength, num_tokens, batch_size=16, max_tokens_per_gen=200):\n",
    "    \"\"\"\n",
    "    Ultra-efficient batched token generation using nnsight best practices.\n",
    "    \n",
    "    Args:\n",
    "        steering_strength: Steering coefficient to apply\n",
    "        num_tokens: Total number of tokens to generate\n",
    "        batch_size: Number of prompts to process in parallel\n",
    "        max_tokens_per_gen: Max tokens to generate per prompt per batch\n",
    "    \n",
    "    Returns:\n",
    "        List of token strings\n",
    "    \"\"\"\n",
    "    all_tokens = []\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Batched Generation: steering={steering_strength:+.1f}, batch_size={batch_size}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    iterations = 0\n",
    "    while len(all_tokens) < num_tokens:\n",
    "        iterations += 1\n",
    "        \n",
    "        # Sample batch of random instructions\n",
    "        prompts = [\n",
    "            model.tokenizer.apply_chat_template(\n",
    "                [{\"role\": \"user\", \"content\": random.choice(instructions)}],\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            )\n",
    "            for _ in range(batch_size)\n",
    "        ]\n",
    "        \n",
    "        # Determine tokens to generate this iteration\n",
    "        tokens_needed = num_tokens - len(all_tokens)\n",
    "        tokens_this_gen = min(max_tokens_per_gen, (tokens_needed // batch_size) + 50)\n",
    "        \n",
    "        # Single generation context with batched prompts\n",
    "        with model.generate(max_new_tokens=tokens_this_gen, do_sample=True) as tracer:\n",
    "            # Pass list of prompts to invoke() for batching\n",
    "            with tracer.invoke(prompts):\n",
    "                token_list = nnsight.list().save()\n",
    "                \n",
    "                # Apply intervention to all generation steps\n",
    "                with tracer.all():\n",
    "                    acts = model.model.layers[15].output[0]\n",
    "                    \n",
    "                    # Steer if needed\n",
    "                    if steering_strength != 0.0:\n",
    "                        model.model.layers[15].output[0][:] = acts + steering_strength * weight_tensor\n",
    "                    \n",
    "                    # Collect argmax tokens\n",
    "                    token_ids = model.lm_head.output.argmax(dim=-1)\n",
    "                    token_list.append(token_ids)\n",
    "        \n",
    "        # Process collected tokens\n",
    "        for token_batch in token_list:\n",
    "            if len(all_tokens) >= num_tokens:\n",
    "                break\n",
    "            \n",
    "            # Handle different tensor shapes\n",
    "            if isinstance(token_batch, torch.Tensor):\n",
    "                # Flatten and decode\n",
    "                token_batch_flat = token_batch.flatten().tolist()\n",
    "                for tid in token_batch_flat:\n",
    "                    if len(all_tokens) >= num_tokens:\n",
    "                        break\n",
    "                    token_str = model.tokenizer.decode([tid], skip_special_tokens=False)\n",
    "                    all_tokens.append(token_str)\n",
    "        \n",
    "        # Progress update\n",
    "        progress = len(all_tokens)\n",
    "        if progress % 5000 < batch_size * tokens_this_gen or progress >= num_tokens:\n",
    "            print(f\"  Iteration {iterations:3d} | Progress: {progress:,} / {num_tokens:,} ({100*progress/num_tokens:.1f}%)\")\n",
    "    \n",
    "    print(f\"  âœ“ Complete: {len(all_tokens):,} tokens in {iterations} iterations\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    return all_tokens[:num_tokens]\n",
    "\n",
    "\n",
    "# Example usage (uncomment to run):\n",
    "# print(\"Testing ultra-efficient batched generation...\")\n",
    "# test_tokens = generate_batched_tokens(0.0, 1000, batch_size=16, max_tokens_per_gen=100)\n",
    "# print(f\"Generated {len(test_tokens)} tokens\")\n",
    "# print(f\"Sample tokens: {test_tokens[:20]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6030d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "# STARTING OPTIMIZED BATCHED TOKEN GENERATION\n",
      "#\n",
      "# Target: 50,000 tokens per condition\n",
      "# Batch Size: 32\n",
      "# Expected speedup: ~32x faster\n",
      "################################################################################\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Batched Generation: steering=+0.0, batch_size=32\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ðŸš€ READY TO RUN: Optimized batch generation\n",
    "# This replaces the original sequential generation with efficient batching\n",
    "\n",
    "# Adjust these for your A40:\n",
    "BATCH_SIZE_OPTIMIZED = 32  # Increase to 24-32 if VRAM allows\n",
    "MAX_TOKENS_PER_GEN = 1000   # Tokens per prompt per iteration\n",
    "TARGET_TOKENS = 50000\n",
    "STEERING_UP = 10.0\n",
    "STEERING_DOWN = -10.0\n",
    "\n",
    "\n",
    "print(f\"\\n{'#'*80}\")\n",
    "print(f\"# STARTING OPTIMIZED BATCHED TOKEN GENERATION\")\n",
    "print(f\"#\")\n",
    "print(f\"# Target: {TARGET_TOKENS:,} tokens per condition\")\n",
    "print(f\"# Batch Size: {BATCH_SIZE_OPTIMIZED}\")\n",
    "print(f\"# Expected speedup: ~{BATCH_SIZE_OPTIMIZED}x faster\")\n",
    "print(f\"{'#'*80}\\n\")\n",
    "\n",
    "# Generate with batching\n",
    "baseline_tokens = generate_batched_tokens(0.0, TARGET_TOKENS, \n",
    "                                         batch_size=BATCH_SIZE_OPTIMIZED, \n",
    "                                         max_tokens_per_gen=MAX_TOKENS_PER_GEN)\n",
    "\n",
    "steered_up_tokens = generate_batched_tokens(STEERING_UP, TARGET_TOKENS,\n",
    "                                           batch_size=BATCH_SIZE_OPTIMIZED,\n",
    "                                           max_tokens_per_gen=MAX_TOKENS_PER_GEN)\n",
    "\n",
    "steered_down_tokens = generate_batched_tokens(STEERING_DOWN, TARGET_TOKENS,\n",
    "                                             batch_size=BATCH_SIZE_OPTIMIZED,\n",
    "                                             max_tokens_per_gen=MAX_TOKENS_PER_GEN)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ðŸŽ‰ GENERATION COMPLETE!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Baseline:     {len(baseline_tokens):,} tokens\")\n",
    "print(f\"Steered Up:   {len(steered_up_tokens):,} tokens\")\n",
    "print(f\"Steered Down: {len(steered_down_tokens):,} tokens\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Analyze distributions\n",
    "print(\"Analyzing token distributions...\")\n",
    "results_df = analyze_token_distributions_robust(baseline_tokens, steered_up_tokens, steered_down_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e3c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nnsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š COMPARE: Original vs Robust Analysis\n",
    "# This cell demonstrates the difference between the two approaches\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPARISON: Biased vs Unbiased Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run ORIGINAL analysis (may be biased by rare tokens)\n",
    "print(\"\\nðŸ”´ ORIGINAL ANALYSIS (potentially biased by rare tokens):\")\n",
    "print(\"-\"*80)\n",
    "results_df_original = analyze_token_distributions(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens, top_n=50\n",
    ")\n",
    "\n",
    "# Run ROBUST analysis (filters rare tokens, includes stats)\n",
    "print(\"\\n\\nðŸŸ¢ ROBUST ANALYSIS (filters rare tokens, includes significance testing):\")\n",
    "print(\"-\"*80)\n",
    "results_df_robust = analyze_token_distributions_robust(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens, \n",
    "    min_total_count=10,  # Adjust based on your total token count\n",
    "    top_n=50\n",
    ")\n",
    "\n",
    "# Compare top results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON OF TOP 10 ENRICHED TOKENS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top10_original = set(results_df_original.nlargest(10, 'up_enrichment')['token'])\n",
    "top10_robust = set(results_df_robust.nlargest(10, 'up_enrichment')['token'])\n",
    "\n",
    "only_in_original = top10_original - top10_robust\n",
    "only_in_robust = top10_robust - top10_original\n",
    "in_both = top10_original & top10_robust\n",
    "\n",
    "print(f\"\\nâœ“ Tokens in both analyses: {len(in_both)}/10\")\n",
    "if in_both:\n",
    "    print(f\"  {', '.join(list(in_both)[:5])}\" + (\"...\" if len(in_both) > 5 else \"\"))\n",
    "\n",
    "print(f\"\\nâš ï¸  Only in ORIGINAL (likely rare token artifacts): {len(only_in_original)}/10\")\n",
    "if only_in_original:\n",
    "    for token in only_in_original:\n",
    "        row = results_df_original[results_df_original['token'] == token].iloc[0]\n",
    "        print(f\"  '{token[:20]}': up={row['up_count']}, baseline={row['baseline_count']}\")\n",
    "\n",
    "print(f\"\\nâœ… Only in ROBUST (filtered signal): {len(only_in_robust)}/10\")\n",
    "if only_in_robust:\n",
    "    for token in only_in_robust:\n",
    "        row = results_df_robust[results_df_robust['token'] == token].iloc[0]\n",
    "        sig = \"***\" if row['up_significant'] else \"\"\n",
    "        print(f\"  '{token[:20]}': up={row['up_count']}, baseline={row['baseline_count']}, total={row['total_count']} {sig}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION: Use the ROBUST analysis for reliable results!\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84efba5",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Recommended Analysis Settings\n",
    "\n",
    "Use these `min_total_count` values based on your dataset size:\n",
    "\n",
    "| Total Tokens per Condition | Recommended `min_total_count` | Reasoning |\n",
    "|----------------------------|------------------------------|-----------|\n",
    "| 1,000 - 10,000 | **5** | Very small dataset, need to keep more tokens |\n",
    "| 10,000 - 100,000 | **10** | Default, good balance |\n",
    "| 100,000 - 1,000,000 | **50** | Medium dataset, filter more noise |\n",
    "| 1,000,000+ | **100-200** | Large dataset, can be more stringent |\n",
    "\n",
    "## Quick Reference:\n",
    "\n",
    "```python\n",
    "# For small test runs (10k tokens):\n",
    "results_df = analyze_token_distributions_robust(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens, \n",
    "    min_total_count=5\n",
    ")\n",
    "\n",
    "# For medium runs (100k tokens):\n",
    "results_df = analyze_token_distributions_robust(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens, \n",
    "    min_total_count=10  # default\n",
    ")\n",
    "\n",
    "# For large runs (1M tokens):\n",
    "results_df = analyze_token_distributions_robust(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens, \n",
    "    min_total_count=100\n",
    ")\n",
    "```\n",
    "\n",
    "## Alternative: Filter by Frequency Instead\n",
    "\n",
    "If you want to filter by **frequency** rather than raw count:\n",
    "\n",
    "```python\n",
    "# Only include tokens that appear in at least 0.01% of samples\n",
    "min_freq = 0.0001  # 0.01%\n",
    "min_count = int(len(baseline_tokens) * min_freq)\n",
    "\n",
    "results_df = analyze_token_distributions_robust(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens, \n",
    "    min_total_count=min_count\n",
    ")\n",
    "```\n",
    "\n",
    "## Exporting Significant Results Only\n",
    "\n",
    "```python\n",
    "# Get only statistically significant enriched tokens\n",
    "significant_up = results_df_robust[\n",
    "    (results_df_robust['up_significant'] == True) & \n",
    "    (results_df_robust['up_enrichment'] > 0)\n",
    "].sort_values('up_enrichment', ascending=False)\n",
    "\n",
    "significant_down = results_df_robust[\n",
    "    (results_df_robust['down_significant'] == True) & \n",
    "    (results_df_robust['down_enrichment'] > 0)\n",
    "].sort_values('down_enrichment', ascending=False)\n",
    "\n",
    "print(f\"Significant enriched tokens (steering up): {len(significant_up)}\")\n",
    "print(f\"Significant enriched tokens (steering down): {len(significant_down)}\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14129d7",
   "metadata": {},
   "source": [
    "# ðŸ“ Summary: Addressing \"Tokens That Don't Appear\" Bias\n",
    "\n",
    "## Yes, the original analysis WAS skewed! \n",
    "\n",
    "### The Problem:\n",
    "Tokens appearing in one condition but not another got **artificially inflated enrichment scores** due to:\n",
    "1. Tiny pseudocount (1e-10) creating extreme ratios\n",
    "2. No filtering of rare tokens\n",
    "3. No statistical significance testing\n",
    "\n",
    "### Example:\n",
    "```\n",
    "Token \"xyz\": appears 3 times in steered_up, 0 times in baseline\n",
    "âŒ Original enrichment: +32.5 (massive!)\n",
    "âœ… Reality: Just random noise, not meaningful\n",
    "```\n",
    "\n",
    "### The Solution:\n",
    "Use `analyze_token_distributions_robust()` which:\n",
    "- âœ… Filters tokens with < `min_total_count` total appearances\n",
    "- âœ… Uses proper Laplace smoothing\n",
    "- âœ… Includes chi-square significance tests\n",
    "- âœ… Applies Bonferroni correction for multiple testing\n",
    "- âœ… Marks statistically significant results with `***`\n",
    "\n",
    "### Key Takeaways:\n",
    "1. **Always use `min_total_count` filtering** (at least 10 for most cases)\n",
    "2. **Focus on tokens marked as significant (`***`)**\n",
    "3. **Larger datasets allow more stringent filtering** (min_count=50-100 for 1M tokens)\n",
    "4. **Enrichment score + significance** = reliable results\n",
    "\n",
    "The robust analysis ensures you're finding **real signal, not noise**! ðŸŽ¯\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0959bd0c",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Quick Reference Card: Unbiased Token Analysis\n",
    "\n",
    "## âœ… DO THIS:\n",
    "```python\n",
    "# Use robust analysis with appropriate filtering\n",
    "results_df = analyze_token_distributions_robust(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens,\n",
    "    min_total_count=10,  # Adjust based on dataset size\n",
    "    top_n=100\n",
    ")\n",
    "\n",
    "# Focus on statistically significant results\n",
    "significant_tokens = results_df[results_df['up_significant'] == True]\n",
    "```\n",
    "\n",
    "## âŒ DON'T DO THIS:\n",
    "```python\n",
    "# Original function without filtering - BIASED!\n",
    "results_df = analyze_token_distributions(\n",
    "    baseline_tokens, steered_up_tokens, steered_down_tokens\n",
    ")\n",
    "# âš ï¸ Results dominated by rare tokens that appeared by chance\n",
    "```\n",
    "\n",
    "## ðŸ” Interpreting Results:\n",
    "\n",
    "### Enrichment Score:\n",
    "- **+1.0** = 2x more frequent\n",
    "- **+2.0** = 4x more frequent  \n",
    "- **+3.0** = 8x more frequent\n",
    "- **-1.0** = 2x less frequent (50% reduction)\n",
    "\n",
    "### Significance Markers:\n",
    "- **`***`** = Statistically significant (p < 0.01 after Bonferroni correction)\n",
    "- No marker = Not statistically significant (could be noise)\n",
    "\n",
    "### What to Report:\n",
    "Focus on tokens that are **BOTH**:\n",
    "1. Highly enriched (|enrichment| > 1.0)\n",
    "2. Statistically significant (marked with `***`)\n",
    "\n",
    "## ðŸ’¡ Pro Tip:\n",
    "For very large datasets (1M+ tokens), increase `min_total_count` to 50-100 to be more stringent and reduce false positives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf83696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Visualize the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get top enriched tokens for each condition\n",
    "top_up = results_df.nlargest(30, 'up_enrichment')\n",
    "top_down = results_df.nlargest(30, 'down_enrichment')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Plot 1: Steered Up enrichment\n",
    "axes[0].barh(range(len(top_up)), top_up['up_enrichment'], color='coral')\n",
    "axes[0].set_yticks(range(len(top_up)))\n",
    "axes[0].set_yticklabels([t[:20] for t in top_up['token']], fontsize=8)\n",
    "axes[0].set_xlabel('Log2 Enrichment vs Baseline', fontsize=10)\n",
    "axes[0].set_title(f'Top 30 Tokens Enriched in STEERED UP\\n(Steering: {STEERING_UP:+.1f})', fontsize=12, fontweight='bold')\n",
    "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Plot 2: Steered Down enrichment\n",
    "axes[1].barh(range(len(top_down)), top_down['down_enrichment'], color='lightblue')\n",
    "axes[1].set_yticks(range(len(top_down)))\n",
    "axes[1].set_yticklabels([t[:20] for t in top_down['token']], fontsize=8)\n",
    "axes[1].set_xlabel('Log2 Enrichment vs Baseline', fontsize=10)\n",
    "axes[1].set_title(f'Top 30 Tokens Enriched in STEERED DOWN\\n(Steering: {STEERING_DOWN:+.1f})', fontsize=12, fontweight='bold')\n",
    "axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResults dataframe shape: {results_df.shape}\")\n",
    "print(f\"Access via: results_df\")\n",
    "print(f\"\\nExample queries:\")\n",
    "print(f\"  - results_df.nlargest(50, 'up_enrichment')  # Most enriched when steering up\")\n",
    "print(f\"  - results_df.nsmallest(50, 'up_enrichment')  # Most depleted when steering up\")\n",
    "print(f\"  - results_df.nlargest(50, 'down_enrichment')  # Most enriched when steering down\")\n",
    "print(f\"  - results_df[results_df['token'].str.contains('word')]  # Search for specific tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a92622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ IMPROVED: Visualize robust results with significance markers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get top enriched tokens for each condition from ROBUST analysis\n",
    "top_up = results_df.nlargest(30, 'up_enrichment')\n",
    "top_down = results_df.nlargest(30, 'down_enrichment')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 10))\n",
    "\n",
    "# Plot 1: Steered Up enrichment with significance markers\n",
    "colors_up = ['red' if sig else 'coral' for sig in top_up['up_significant']]\n",
    "bars1 = axes[0].barh(range(len(top_up)), top_up['up_enrichment'], color=colors_up)\n",
    "axes[0].set_yticks(range(len(top_up)))\n",
    "axes[0].set_yticklabels([t[:20] for t in top_up['token']], fontsize=8)\n",
    "axes[0].set_xlabel('Log2 Enrichment vs Baseline', fontsize=11)\n",
    "axes[0].set_title(f'Top 30 Tokens Enriched in STEERED UP\\n(Steering: {STEERING_UP:+.1f})\\nRed = Statistically Significant (p < 0.01)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[0].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Add total count annotations\n",
    "for i, (idx, row) in enumerate(top_up.iterrows()):\n",
    "    axes[0].text(row['up_enrichment'] + 0.1, i, f\"n={row['total_count']}\", \n",
    "                va='center', fontsize=7, color='darkred' if row['up_significant'] else 'gray')\n",
    "\n",
    "# Plot 2: Steered Down enrichment with significance markers\n",
    "colors_down = ['darkblue' if sig else 'lightblue' for sig in top_down['down_significant']]\n",
    "bars2 = axes[1].barh(range(len(top_down)), top_down['down_enrichment'], color=colors_down)\n",
    "axes[1].set_yticks(range(len(top_down)))\n",
    "axes[1].set_yticklabels([t[:20] for t in top_down['token']], fontsize=8)\n",
    "axes[1].set_xlabel('Log2 Enrichment vs Baseline', fontsize=11)\n",
    "axes[1].set_title(f'Top 30 Tokens Enriched in STEERED DOWN\\n(Steering: {STEERING_DOWN:+.1f})\\nDark Blue = Statistically Significant (p < 0.01)', \n",
    "                  fontsize=12, fontweight='bold')\n",
    "axes[1].axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "# Add total count annotations\n",
    "for i, (idx, row) in enumerate(top_down.iterrows()):\n",
    "    axes[1].text(row['down_enrichment'] + 0.1, i, f\"n={row['total_count']}\", \n",
    "                va='center', fontsize=7, color='darkblue' if row['down_significant'] else 'gray')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('steering_analysis_robust.png', dpi=150, bbox_inches='tight')\n",
    "print(\"âœ“ Saved plot to 'steering_analysis_robust.png'\")\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total unique tokens analyzed: {len(results_df):,}\")\n",
    "print(f\"\\nStatistically significant enrichments:\")\n",
    "print(f\"  Steered UP:   {results_df['up_significant'].sum():,} tokens\")\n",
    "print(f\"  Steered DOWN: {results_df['down_significant'].sum():,} tokens\")\n",
    "\n",
    "print(f\"\\nTop 10 significant tokens (steering UP):\")\n",
    "sig_up = results_df[results_df['up_significant']].nlargest(10, 'up_enrichment')\n",
    "for idx, row in sig_up.iterrows():\n",
    "    print(f\"  '{row['token'][:25]:25s}' | enrichment: {row['up_enrichment']:+.2f} | p={row['up_pvalue']:.2e}\")\n",
    "\n",
    "print(f\"\\nTop 10 significant tokens (steering DOWN):\")\n",
    "sig_down = results_df[results_df['down_significant']].nlargest(10, 'down_enrichment')\n",
    "for idx, row in sig_down.iterrows():\n",
    "    print(f\"  '{row['token'][:25]:25s}' | enrichment: {row['down_enrichment']:+.2f} | p={row['down_pvalue']:.2e}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a7998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file for later analysis\n",
    "results_df.to_csv('steering_analysis_results.csv', index=False)\n",
    "print(\"Results saved to 'steering_analysis_results.csv'\")\n",
    "\n",
    "# Also save the raw token lists\n",
    "import json\n",
    "with open('steering_analysis_tokens.json', 'w') as f:\n",
    "    json.dump({\n",
    "        'baseline': baseline_tokens,\n",
    "        'steered_up': steered_up_tokens,\n",
    "        'steered_down': steered_down_tokens,\n",
    "        'config': {\n",
    "            'steering_up': STEERING_UP,\n",
    "            'steering_down': STEERING_DOWN,\n",
    "            'target_tokens': TARGET_TOKENS,\n",
    "            'prompt': PROMPT\n",
    "        }\n",
    "    }, f)\n",
    "print(\"Raw tokens saved to 'steering_analysis_tokens.json'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
